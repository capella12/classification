{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "微调BERT.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQJdRQY9szui"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy31ZJfvXmcK"
      },
      "source": [
        "ConnectButton（）{\n",
        "console.log（\" Connect push\"）; \n",
        "document.querySelector（\"＃top-toolbar> colab-connect- \n",
        "按钮\"）.shadowRoot.querySelector（\"＃connect\"）。click（）\n",
        "} \n",
        "setInterval（ConnectButton，60000）; "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arXyHWTMsOn-"
      },
      "source": [
        "import os\n",
        "os.listdir('/content/drive/MyDrive/bert_cnn_blstm_crf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6nVf5nyPyBg"
      },
      "source": [
        "!pip install kashgari"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXltl9AFQJU4"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn,length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsHQqz__QFtV"
      },
      "source": [
        "def read_corpus(corpus_path):\n",
        "    \"\"\"\n",
        "    read corpus and return the list of samples\n",
        "    :param corpus_path:\n",
        "    :return: data\n",
        "    \"\"\"\n",
        "    pad_size=10\n",
        "    windows_size=75\n",
        "    data = []\n",
        "    with open(corpus_path, encoding='utf-8') as fr:\n",
        "        lines = fr.readlines()\n",
        "    sent_, tag_ = [], []\n",
        "    for line in lines:\n",
        "        [char, label] = line.rstrip().split(' ')\n",
        "        sent_.append(char)\n",
        "        tag_.append(label)\n",
        "    for cur_idx in range(pad_size,len(sent_)-pad_size,windows_size):\n",
        "        chars=sent_[cur_idx-pad_size:cur_idx+windows_size+pad_size]\n",
        "        tags=tag_[cur_idx-pad_size:cur_idx+windows_size+pad_size]\n",
        "        data.append([chars,tags])\n",
        "\n",
        "    return data\n",
        "def get_data(data):\n",
        "    x_data=[]\n",
        "    y_data=[]\n",
        "    for x,y in data:\n",
        "        x_data.append(x)\n",
        "        y_data.append(y)\n",
        "    return x_data,y_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDnkj9XrVxZH"
      },
      "source": [
        "open('/content/drive/MyDrive/bert_cnn_blstm_crf/model_info.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQX3C01xRoqG"
      },
      "source": [
        "test_data = read_corpus('test')\n",
        "test_x,test_y=get_data(test_data)\n",
        "path='/content/drive/MyDrive/bert_cnn_blstm_crf/model_info.json'\n",
        "import kashgari\n",
        "# train_data.extend(test_data)\n",
        "# np.random.seed(200)\n",
        "# np.random.shuffle(train_data)\n",
        "# train=train_data[:round(len(train_data)*args.ratio1)]\n",
        "# dev=train_data[round(len(train_data)*args.ratio1):round(len(train_data)*args.ratio2)]\n",
        "# test=train_data[round(len(train_data)*args.ratio2):]\n",
        "loaded_model=kashgari.utils.load_model(path)\n",
        "    # _,label_predict=loaded_model.evaluate(test_x,test_y)   \n",
        "loaded_model.predict(test_x[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKBC8ZPEs1Cz"
      },
      "source": [
        "# 卷积神经网络函数实现\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwEldwcFs-aO"
      },
      "source": [
        "from mxnet import autograd,nd\n",
        "from mxnet.gluon import nn\n",
        "\n",
        "# def corr2d(X,K):\n",
        "#   h,w=K.shape\n",
        "#   Y=nd.zeros((X.shape[0]-h+1,X.shape[1]-w+1))\n",
        "#   for i in range(Y.shape[0]):\n",
        "#     for j in range(Y.shape[1]):\n",
        "#       Y[i,j]=(X[i:i+h,j:j+w]*K).sum()\n",
        "#   return Y\n",
        "\n",
        "from mxnet import autograd, nd\n",
        "from mxnet.gluon import nn\n",
        "\n",
        "def corr2d(X, K):  # 本函数已保存在d2lzh包中方便以后使用\n",
        "    h, w = K.shape\n",
        "    Y = nd.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
        "    return Y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgLMunQD7d3p"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnvVu6b_7e7X"
      },
      "source": [
        "X = nd.ones((6, 8))\n",
        "X[2:4, :] = 0\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJAPURRq574E"
      },
      "source": [
        "\n",
        "K = nd.array([[-1],[1]])\n",
        "h, w = K.shape\n",
        "corr2d(X,K)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd_ymUSryZM5"
      },
      "source": [
        "X=nd.array([[0,1,2],[3,4,5],[6,7,8]])\n",
        "K=nd.array([[0,1],[2,3]])\n",
        "corr2d(X,K)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-GuGlm-ywR1"
      },
      "source": [
        "class Conv2D(nn.Block):\n",
        "  def __init__(self,kernel_size,**kwargs):\n",
        "    super(Conv2D,self).__init__(**kwargs)\n",
        "    self.weight=self.params.get('weight',shape=kernel_size)\n",
        "    self.bias=self.params.get('bias',shape=(1,))\n",
        "  def forward(self,x):\n",
        "    return corr2d(x,self.weight.data())+self.bias.data()\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4x1b-mh1vQW"
      },
      "source": [
        "X=nd.ones((6,8))\n",
        "X[:,2:6]=0\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7KPEGXi17Ux"
      },
      "source": [
        "K=nd.array([[1,-1]])\n",
        "K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzkTPhzS3d-C"
      },
      "source": [
        "Y=corr2d(X,K)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6r6dcro2TXu"
      },
      "source": [
        "corr2d()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSCG27OyVZCZ"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRF8FqPKsKm6"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('{name},{length}'.format(name=fn,length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kujelW3saA4p"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn,length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzFqPeujbusu"
      },
      "source": [
        "open('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tsq4qHoeNP0"
      },
      "source": [
        "!pip install d2lzh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmluJPHWxF4k"
      },
      "source": [
        "open('train_augmented.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBevSJ-EeMvq"
      },
      "source": [
        "!pip install mxnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcPzkY6eelQ3"
      },
      "source": [
        "import d2lzh as d2l\n",
        "from mxnet import autograd,gluon,init,nd\n",
        "from mxnet.gluon import data as gdata,loss as gloss,nn\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9dr0QCDe7oF"
      },
      "source": [
        "train_data=pd.read_csv('train.csv')\n",
        "test_data=pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56xtVjsjfFjl"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAJWUGwxfqM7"
      },
      "source": [
        "train_data.iloc[0:4,[0,1,2,3,-3,-2,-1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knyfrl8Kf4cJ"
      },
      "source": [
        "all_features=pd.concat((train_data.iloc[:,1:-1],test_data.iloc[:,1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4Nayjy7hHd0"
      },
      "source": [
        "numeric_features=all_features.dtypes[all_features.dtypes!='object'].index\n",
        "all_features[numeric_features]=all_features[numeric_features].apply(lambda x:(x-x.mean())/(x.std()))\n",
        "all_features[numeric_features]=all_features[numeric_features].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPNJrsRxnFlA"
      },
      "source": [
        "all_features=pd.get_dummies(all_features,dummy_na=True)\n",
        "all_features.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADH9g-xooxyL"
      },
      "source": [
        "n_train=train_data.shape[0]\n",
        "train_features=nd.array(all_features[:n_train].values)\n",
        "test_features=nd.array(all_features[n_train:].values)\n",
        "train_labels=nd.array(train_data.SalePrice.values).reshape((-1,1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcXiFtrppeBO"
      },
      "source": [
        "loss=gloss.L2Loss()\n",
        "def get_net():\n",
        "  net=nn.Sequential()\n",
        "  net.add(nn.Dense(1))\n",
        "  net.initialize()\n",
        "  return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjgmKQUNp_qV"
      },
      "source": [
        "def log_rmse(net,features,labels):\n",
        "  clipped_preds=nd.clip(net(features),1,float('inf'))\n",
        "  rmse=nd.sqrt(2*loss(clipped_preds.log(),labels.log()).mean())\n",
        "  return rmse.asscalar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSCQVEnY5JNk"
      },
      "source": [
        "def train(net, train_features, train_labels, test_features, test_labels,\n",
        "          num_epochs, learning_rate, weight_decay, batch_size):\n",
        "    train_ls, test_ls = [], []\n",
        "    train_iter = gdata.DataLoader(gdata.ArrayDataset(\n",
        "        train_features, train_labels), batch_size, shuffle=True)\n",
        "    # 这里使用了Adam优化算法\n",
        "    trainer = gluon.Trainer(net.collect_params(), 'adam', {\n",
        "        'learning_rate': learning_rate, 'wd': weight_decay})\n",
        "    for epoch in range(num_epochs):\n",
        "        for X, y in train_iter:\n",
        "            with autograd.record():\n",
        "                l = loss(net(X), y)\n",
        "            l.backward()\n",
        "            trainer.step(batch_size)\n",
        "        train_ls.append(log_rmse(net, train_features, train_labels))\n",
        "        if test_labels is not None:\n",
        "            test_ls.append(log_rmse(net, test_features, test_labels))\n",
        "    return train_ls, test_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmV2HgC_4MzI"
      },
      "source": [
        "def get_k_fold_data(k, i, X, y):\n",
        "    assert k > 1\n",
        "    fold_size = X.shape[0] // k\n",
        "    X_train, y_train = None, None\n",
        "    for j in range(k):\n",
        "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
        "        X_part, y_part = X[idx, :], y[idx]\n",
        "        if j == i:\n",
        "            X_valid, y_valid = X_part, y_part\n",
        "        elif X_train is None:\n",
        "            X_train, y_train = X_part, y_part\n",
        "        else:\n",
        "            X_train = nd.concat(X_train, X_part, dim=0)\n",
        "            y_train = nd.concat(y_train, y_part, dim=0)\n",
        "    return X_train, y_train, X_valid, y_valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sckKk-kN4T6P"
      },
      "source": [
        "def k_fold(k, X_train, y_train, num_epochs,\n",
        "           learning_rate, weight_decay, batch_size):\n",
        "    train_l_sum, valid_l_sum = 0, 0\n",
        "    for i in range(k):\n",
        "        data = get_k_fold_data(k, i, X_train, y_train)\n",
        "        net = get_net()\n",
        "        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,\n",
        "                                   weight_decay, batch_size)\n",
        "        train_l_sum += train_ls[-1]\n",
        "        valid_l_sum += valid_ls[-1]\n",
        "        if i == 0:\n",
        "            d2l.semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'rmse',\n",
        "                         range(1, num_epochs + 1), valid_ls,\n",
        "                         ['train', 'valid'])\n",
        "        print('fold %d, train rmse %f, valid rmse %f'\n",
        "              % (i, train_ls[-1], valid_ls[-1]))\n",
        "    return train_l_sum / k, valid_l_sum / k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvie5KH74oR1"
      },
      "source": [
        "\n",
        "k, num_epochs, lr, weight_decay, batch_size = 5, 100, 5, 0, 64\n",
        "train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr,\n",
        "                          weight_decay, batch_size)\n",
        "print('%d-fold validation: avg train rmse %f, avg valid rmse %f'\n",
        "      % (k, train_l, valid_l))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUfimKsWu7Iq"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4e4R-Q7vkz-"
      },
      "source": [
        "open('rel_dict.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITeSsFoqwCiV"
      },
      "source": [
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIpBM6RdYa8E"
      },
      "source": [
        "def read_txt_file(file_path):\n",
        "    data=[]\n",
        "    dic=load()\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        content=[]\n",
        "        for line in f.readlines():\n",
        "            if line is not '\\n':\n",
        "                line=line.rstrip()\n",
        "                line=line.replace(' ', '')\n",
        "                content.append(line)\n",
        "    # labels, texts,word= [], [],[]\n",
        "    word=[]\n",
        "    for line in content:\n",
        "        parts = line.split('\\t')\n",
        "        label, text = parts[0], ''.join(parts[1:])\n",
        "        label=dic[int(label)]\n",
        "        for i in text:\n",
        "            word.append(i)\n",
        "        # labels.append(label)\n",
        "        # texts.append(word)\n",
        "        data.append((label,word))\n",
        "        word=[]\n",
        "        \n",
        "    return data\n",
        "def load():\n",
        "  with open('rel_dict.json','r',encoding='utf-8') as h:\n",
        "    data=json.load(h)\n",
        "    data={v:k for k,v in data.items()}\n",
        "  return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxtnBp1WqcfC"
      },
      "source": [
        "def get_data(data):\n",
        "  x_data=[]\n",
        "  y_data=[]\n",
        "  for idx in data:\n",
        "    x_data.append(idx[1])\n",
        "    y_data.append(idx[0])\n",
        "  return x_data,y_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2mGYDck91l_"
      },
      "source": [
        "data=read_txt_file('train.txt')\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(200)\n",
        "np.random.shuffle(data)\n",
        "train_data=data[:round(len(data)*0.8)]\n",
        "val_data=data[round(len(data)*0.6):round(len(data)*0.8)]\n",
        "test_data=data[round(len(data)*0.8):]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGKJZnd5QlLF"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Af1re7BqZh4"
      },
      "source": [
        "train_x,train_y=get_data(train_data)\n",
        "val_x,val_y=get_data(val_data)\n",
        "test_x,test_y=get_data(test_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UORl-ZheQY0w"
      },
      "source": [
        "!pip install kashgari"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KyrfCzbOaIM"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq12Cix4OQk1"
      },
      "source": [
        "import kashgari\n",
        "from tensorflow.python import keras\n",
        "from kashgari.tasks.classification import CNN_Model\n",
        "\n",
        "from kashgari.callbacks import EvalCallBack\n",
        "from kashgari.embeddings import BareEmbedding,BertEmbedding\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9fPHs2HQrte"
      },
      "source": [
        "from typing import Dict,Any\n",
        "from tensorflow import keras\n",
        "\n",
        "from kashgari.tasks.classification.abc_model import ABCClassificationModel\n",
        "from kashgari.layers import L\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level='DEBUG')\n",
        "\n",
        "\n",
        "class CNN_BiLSTM_Model(ABCClassificationModel):\n",
        "    \"\"\"Bidirectional LSTM Sequence Labeling Model\"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def default_hyper_parameters(cls) -> Dict[str, Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Get hyper parameters of model\n",
        "        Returns:\n",
        "            hyper parameters dict\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'layer_blstm1': {\n",
        "                'units': 128,\n",
        "                'return_sequences': True\n",
        "            },\n",
        "            'layer_blstm2': {\n",
        "                'units': 128,\n",
        "                'return_sequences': False\n",
        "            },\n",
        "            'layer_dropout': {\n",
        "                'rate': 0.4\n",
        "            },\n",
        "            'layer_time_distributed': {},\n",
        "            'layer_output': {\n",
        "\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def build_model_arc(self):\n",
        "        \"\"\"\n",
        "        build model architectural\n",
        "        \"\"\"\n",
        "        output_dim = len(self.processor.label2idx)\n",
        "        config = self.hyper_parameters\n",
        "        embed_model = self.embedding.embed_model\n",
        "\n",
        "        # Define your layers\n",
        "        layer_blstm1 = L.Bidirectional(L.LSTM(**config['layer_blstm1']),\n",
        "                                       name='layer_blstm1')\n",
        "        layer_blstm2 = L.Bidirectional(L.LSTM(**config['layer_blstm2']),\n",
        "                                       name='layer_blstm2')\n",
        "\n",
        "        layer_dropout = L.Dropout(**config['layer_dropout'],\n",
        "                                  name='layer_dropout')\n",
        "\n",
        "        layer_time_distributed = L.Dense(output_dim, **config['layer_output'])\n",
        "\n",
        "        # You need to use this actiovation layer as final activation\n",
        "        # to suppor multi-label classification\n",
        "        layer_activation = self._activation_layer()\n",
        "        tensor=embed_model.output\n",
        "        kernel_sizes=[7,7,7]\n",
        "        for kernel_size in kernel_sizes:\n",
        "            tensor=L.Conv1D(128,kernel_size=kernel_size)(tensor)\n",
        "            tensor=L.MaxPool1D()(tensor)\n",
        "        lstm=layer_blstm1(embed_model.output)\n",
        "        tensor=L.Conv1D(128,kernel_size=7)(tensor)\n",
        "        tensor=L.GlobalMaxPool1D()(tensor)  \n",
        "    \n",
        "        output=L.concatenate([tensor,lstm],axis=1)\n",
        "        output_tensor=L.Dense(output_dim,activation='softmax')(output)\n",
        "  \n",
        "        \n",
        "        # Define tensor flow\n",
        "        \n",
        "        # Init model\n",
        "        self.tf_model = keras.Model(embed_model.inputs, output_tensor)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asL7sBLEKOKs"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.optimizers.Adam()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQPP0pfHKqhD"
      },
      "source": [
        "model=CNN_Model()\n",
        "model.build_model(train_x,train_y)\n",
        "\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "model.compile_model(optimizer=optimizer)\n",
        "tf_board_callback=keras.callbacks.TensorBoard()\n",
        "eval_callback=EvalCallBack(model,val_x,val_y,step=1)\n",
        "history=model.fit(train_x,train_y,val_x,val_y,batch_size=8,epochs=40,callbacks=[eval_callback,tf_board_callback])\n",
        "model.evaluate(test_x,test_y)\n",
        "\n",
        "model.evaluate(test_x,test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSFrs6ui3IkU"
      },
      "source": [
        "# 新段落"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yULVLaafHmbm"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY_tk1h2LgYP"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot()\n",
        "epochs = len(history.history['loss'])\n",
        "plt.plot(range(epochs), history.history['loss'], label='loss')\n",
        "plt.plot(range(epochs), history.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.savefig(\"loss_acc.svg\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj6l8FcqHn0E"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('loss_acc.svg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3ODz3zD72Cg"
      },
      "source": [
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWIgX5DU74eq"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOAQ_W_mGwhC"
      },
      "source": [
        "!wget -O /usr/share/fonts/truetype/liberation/simhei.ttf \"https://www.wfonts.com/download/data/2014/06/01/simhei/chinese.simhei.ttf\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWl6ISjUGmWd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "zhfont = mpl.font_manager.FontProperties(fname='/usr/share/fonts/truetype/liberation/simhei.ttf')\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr0JVxpF06Dz"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "zhfont = mpl.font_manager.FontProperties(fname='/usr/share/fonts/truetype/liberation/simhei.ttf')\n",
        "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
        "plt.xlabel(u'词语', fontproperties=zhfont)\n",
        "plt.ylabel(u'特征重要度', fontproperties=zhfont)\n",
        "plt.xticks(fontproperties=zhfont)\n",
        "plt.bar(imp_plot['name'],imp_plot['imp'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYPefI9Z8IHt"
      },
      "source": [
        "%matplotlib inline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "\n",
        "def plot_confusion_matrix(cm, savename, title='Confusion Matrix'):\n",
        "\n",
        "    plt.figure(figsize=(12, 8), dpi=100)\n",
        "    np.set_printoptions(precision=2)\n",
        "\n",
        "    # 在混淆矩阵中每格的概率值\n",
        "    ind_array = np.arange(len(classes))\n",
        "    x, y = np.meshgrid(ind_array, ind_array)\n",
        "    for x_val, y_val in zip(x.flatten(), y.flatten()):\n",
        "        c = cm[y_val][x_val]\n",
        "        if c > 0.001:\n",
        "            plt.text(x_val, y_val, \"%0.0f\" % (c,), color='red', fontsize=15, va='center', ha='center')\n",
        "    \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.viridis)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    xlocations = np.array(range(len(classes)))\n",
        "    plt.xticks(xlocations, classes, rotation=90)\n",
        "    plt.yticks(xlocations, classes)\n",
        "    plt.ylabel('Actual label')\n",
        "    plt.xlabel('Predict label')\n",
        "     \n",
        "    #指定默认字体  \n",
        "    #解决负号'-'显示为方块的问题   \n",
        "\n",
        "    # offset the tick\n",
        "    tick_marks = np.array(range(len(classes))) + 0.5\n",
        "    plt.gca().set_xticks(tick_marks, minor=True,fontproperties=zhfont)\n",
        "    plt.gca().set_yticks(tick_marks, minor=True,fontproperties=zhfont)\n",
        "    plt.gca().xaxis.set_ticks_position('none')\n",
        "    plt.gca().yaxis.set_ticks_position('none')\n",
        "    plt.grid(True, which='minor', linestyle='-')\n",
        "    plt.gcf().subplots_adjust(bottom=0.15)\n",
        "    \n",
        "    # show confusion matrix\n",
        "    plt.savefig(savename, format='svg')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_1Q4EnE_Z7W"
      },
      "source": [
        "with open('rel_dict.json') as f:\n",
        "  data=json.load(f)\n",
        "rel=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUzb32q7BcGa"
      },
      "source": [
        "len(data.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWL-uUq79ceC"
      },
      "source": [
        "# classes表示不同类别的名称，比如这有6个类别\n",
        "classes = data.keys()\n",
        "line=open('rel_dict.json')\n",
        "  # 6个类别，随机生成50个样本\n",
        "y_pred= model.predict(test_x)  # 样本实际标签\n",
        "  # 将前10个样本的值进行随机更改\n",
        " # 样本预测标签\n",
        "y_true=test_y\n",
        "# 获取混淆矩阵\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plot_confusion_matrix(cm, 'confusion_matrix.svg', title='confusion matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s39NcVu6Ob6k"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('confusion_matrix.svg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDc-SyxpgOdH"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix    # 生成混淆矩阵函数\n",
        "import matplotlib.pyplot as plt    # 绘图库\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-ptK4SYgTlo"
      },
      "source": [
        "def plot_confusion_matrix(cm, labels_name, title):\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]    # 归一化\n",
        "    plt.imshow(cm, interpolation='nearest')    # 在特定的窗口上显示图像\n",
        "    plt.title(title)    # 图像标题\n",
        "    ind_array = np.arange(len(labels_name))\n",
        "    x, y = np.meshgrid(ind_array, ind_array)\n",
        "    for x_val, y_val in zip(x.flatten(), y.flatten()):\n",
        "        c = cm[y_val][x_val]\n",
        "        if c > 0.001:\n",
        "            plt.text(x_val, y_val, \"%0.0f\" % (c,), color='red', fontsize=15, va='center', ha='center')\n",
        "    plt.colorbar()\n",
        "    num_local = np.array(range(len(labels_name)))    \n",
        "    plt.xticks(num_local, labels_name, rotation=90,fontproperties=zhfont)    # 将标签印在x轴坐标上\n",
        "    plt.yticks(num_local, labels_name,fontproperties=zhfont)    # 将标签印在y轴坐标上\n",
        "    plt.ylabel('True label')    \n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtLUCPZ1z8Oe"
      },
      "source": [
        "!wget -O /usr/share/fonts/truetype/liberation/simhei.ttf \"https://www.wfonts.com/download/data/2014/06/01/simhei/chinese.simhei.ttf\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBbygDchglW0"
      },
      "source": [
        "y_true=test_y\n",
        "classes = data.keys()\n",
        "y_pred=model.predict(test_x)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(cm)\n",
        "# [[100   1   0   1   6   0   0]\n",
        "#  [  2 111   3   0   2   1  24]\n",
        "#  [  0   2  68   5   4   3   2]\n",
        "#  [  2   0   1 120   7  26   0]\n",
        "#  [  2   5   3   2 120  11  14]\n",
        "#  [  2   0   2  12   8 115   1]\n",
        "#  [  2  25   0   1  14   4 302]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V79dugVXiVrZ"
      },
      "source": [
        "plot_confusion_matrix(cm, classes, \"HAR Confusion Matrix\")\n",
        "plt.savefig('/HAR_cm.svg', format='svg')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W4epoRjKfEm"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/HAR_cm.svg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1hd_O9V0qEN"
      },
      "source": [
        "!pip install keras_radam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn6lJvQukHt6"
      },
      "source": [
        "from kashgari.tasks.classification import BiLSTM_Model\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "model1=BiLSTM_Model()\n",
        "model1.build_model(train_x,train_y)\n",
        "optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
        "model1.compile_model(optimizer=optimizer)\n",
        "tf_board_callback=keras.callbacks.TensorBoard()\n",
        "eval_callback=EvalCallBack(model,val_x,val_y,step=1)\n",
        "history=model1.fit(train_x,train_y,val_x,val_y,batch_size=8,epochs=40,callbacks=[eval_callback,tf_board_callback])\n",
        "model1.evaluate(test_x,test_y)\n",
        "\n",
        "model.evaluate(test_x,test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbbFFzpSBs01"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm,target_names,title='Confusion matrix',cmap=plt.cm.Reds,#设置混淆矩阵的颜色主题normalize=True):\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(15, 12))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "   \n",
        "    plt.show()\n",
        "\n",
        "def plot_confuse(model, x_val, y_val, labels):\n",
        "    predictions = model.predict_classes(x_val,batch_size=batch)\n",
        "    truelabel = y_val.argmax(axis=-1)   # 将one-hot转化为label\n",
        "    conf_mat = confusion_matrix(y_true=truelabel, y_pred=predictions)\n",
        "    plt.figure()\n",
        "    plot_confusion_matrix(conf_mat, normalize=False,target_names=labels,title='Confusion Matrix')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pL81ofP7EnY"
      },
      "source": [
        "!pip install kashgari"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r2GfPe97HRK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}